input {
  # ML Model Inference Logs via TCP
  tcp {
    port => 5001
    codec => json_lines
    type => "model_inference"
    tags => ["ml_metrics"]
  }
  
  # Data Pipeline Logs via TCP
  tcp {
    port => 5002
    codec => json_lines
    type => "data_pipeline"
    tags => ["pipeline_logs"]
  }
  
  # File input for batch processing
  file {
    path => "/usr/share/logstash/ml-logs/*.json"
    start_position => "beginning"
    sincedb_path => "/dev/null"
    codec => "json"
    tags => ["batch_logs"]
  }
}

filter {
  # Add timestamp if missing
  if ![timestamp] {
    ruby {
      code => "event.set('timestamp', Time.now.utc.iso8601)"
    }
  }
  
  # Parse timestamp
  date {
    match => [ "timestamp", "ISO8601", "yyyy-MM-dd HH:mm:ss", "yyyy-MM-dd'T'HH:mm:ss.SSSZ" ]
    target => "@timestamp"
  }
  
  # ML Model Inference Processing
  if [type] == "model_inference" {
    
    # Calculate prediction confidence category
    if [prediction_confidence] {
      if [prediction_confidence] >= 0.9 {
        mutate { 
          add_field => { "confidence_level" => "high" }
        }
      } else if [prediction_confidence] >= 0.7 {
        mutate { 
          add_field => { "confidence_level" => "medium" }
        }
      } else {
        mutate { 
          add_field => { "confidence_level" => "low" }
          add_tag => ["low_confidence_prediction"]
        }
      }
    }
    
    # Flag slow inferences
    if [inference_time_ms] > 100 {
      mutate { 
        add_tag => ["slow_inference"]
        add_field => { "performance_alert" => true }
      }
    }
    
    # Detect prediction accuracy
    if [prediction_class] and [true_label] {
      ruby {
        code => '
          pred = event.get("prediction_class")
          true_val = event.get("true_label")
          if pred == true_val
            event.set("prediction_correct", true)
            event.set("prediction_result", "correct")
          else
            event.set("prediction_correct", false)
            event.set("prediction_result", "incorrect")
            event.tag("misclassification")
          end
        '
      }
    }
    
    # Add inference latency categories
    if [inference_time_ms] {
      if [inference_time_ms] <= 10 {
        mutate { add_field => { "latency_category" => "fast" } }
      } else if [inference_time_ms] <= 50 {
        mutate { add_field => { "latency_category" => "normal" } }
      } else if [inference_time_ms] <= 100 {
        mutate { add_field => { "latency_category" => "slow" } }
      } else {
        mutate { add_field => { "latency_category" => "very_slow" } }
      }
    }
    
    # Enrich with model metadata
    if [model_name] {
      mutate {
        add_field => { 
          "index_name" => "ml-metrics-%{+YYYY.MM.dd}"
        }
      }
    }
  }
  
  # Data Pipeline Processing
  if [type] == "data_pipeline" {
    
    # Flag data quality issues
    if [data_quality_score] and [data_quality_score] < 0.7 {
      mutate {
        add_tag => ["data_quality_issue"]
        add_field => { "quality_alert" => true }
      }
    }
    
    # Process pipeline stages
    if [pipeline_stage] {
      mutate {
        add_field => { 
          "index_name" => "data-pipeline-%{+YYYY.MM.dd}"
        }
      }
    }
  }
  
  # Error Detection for all types
  if [error] or [error_message] {
    mutate {
      add_tag => ["error_event"]
      add_field => { "has_error" => true }
    }
    
    # Classify error severity
    if [error_message] {
      if [error_message] =~ /timeout|TimeoutError/ {
        mutate { add_field => { "error_type" => "timeout" } }
      } else if [error_message] =~ /memory|OOM|OutOfMemory/ {
        mutate { add_field => { "error_type" => "memory" } }
      } else if [error_message] =~ /connection|network/ {
        mutate { add_field => { "error_type" => "network" } }
      } else {
        mutate { add_field => { "error_type" => "unknown" } }
      }
    }
  }
  
  # Resource monitoring
  if [cpu_usage] and [cpu_usage] > 80 {
    mutate { add_tag => ["high_cpu_usage"] }
  }
  
  if [memory_usage_mb] and [memory_usage_mb] > 4096 {
    mutate { add_tag => ["high_memory_usage"] }
  }
  
  # Remove unnecessary fields
  mutate {
    remove_field => ["host", "port", "@version"]
  }
}

output {
  # Send to Elasticsearch with dynamic index naming
  elasticsearch {
    hosts => ["elasticsearch:9200"]
    index => "%{[index_name]}"
    document_id => "%{request_id}"
    template_name => "ml-metrics-template"
  }
  
  # Fallback for logs without index_name
  if ![index_name] {
    elasticsearch {
      hosts => ["elasticsearch:9200"]
      index => "ml-general-%{+YYYY.MM.dd}"
    }
  }
  
  # Console output for debugging (remove in production)
  stdout {
    codec => rubydebug {
      metadata => false
    }
  }
  
  # Alert on critical events
  if "error_event" in [tags] or "slow_inference" in [tags] {
    stdout {
      codec => line {
        format => "ALERT: %{@timestamp} - %{model_name} - %{error_type} - %{message}"
      }
    }
  }
}
